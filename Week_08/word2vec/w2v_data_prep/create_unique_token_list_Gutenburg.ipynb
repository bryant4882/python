{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Unique Word list from Gutenburg\n",
    "\n",
    "This notebook is a variation based on Anna's [Get Unique Token Jupyter Notebook](http://localhost:8891/notebooks/data_prep/create_unique_token_list.ipynb)\n",
    "\n",
    "We are going to directly get text corpus from NLTK's Gutenberg collection. Project Gutenberg contains 60,000 public domain e-books made available for non-commercial use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Gutenberg corpus\n",
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887071\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly\n"
     ]
    }
   ],
   "source": [
    "# Let's get Jane Austen's \"Emma\"\n",
    "emma_text = gutenberg.raw('austen-emma.txt')\n",
    "print(len(emma_text))\n",
    "print(emma_text[50:218])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get words and clean words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import re, which stands for regular expression\n",
    "import re\n",
    "\n",
    "# Define a pattern using a regular expression\n",
    "pattern = r\"[^a-z]\"\n",
    "\n",
    "# Search for the pattern, and replace every instance\n",
    "# with a replacement string\n",
    "emma_txt = re.sub(pattern, ' ', emma_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161977"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma_wordlist = re.split(r\" +\", emma_txt)\n",
    "len(emma_wordlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep only unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list where we'll store exactly one\n",
    "# of each token\n",
    "unique_token_list = []\n",
    "\n",
    "# For each token in the dialogue list,\n",
    "for token in emma_wordlist:\n",
    "    # if (and only if) that token is not yet in the unique list\n",
    "    if token not in unique_token_list:\n",
    "        # add it to the unique list\n",
    "        unique_token_list.append(token)\n",
    "\n",
    "# Sort the list, so it'll be easier\n",
    "# to spot duplicates if they exist\n",
    "unique_token_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7094\n",
      "['active', 'activity', 'actual', 'actually', 'acute', 'acuteness', 'adair', 'adapt', 'add', 'added', 'adding', 'addition', 'additional', 'address', 'addressed', 'addresses', 'addressing', 'adelaide', 'adequate', 'adherence']\n"
     ]
    }
   ],
   "source": [
    "unique_token_list = unique_token_list[1:]\n",
    "print(len(unique_token_list))\n",
    "print(unique_token_list[100:120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store our words in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('jane_austen_emma.txt', 'w') as f:\n",
    "    for token in unique_token_list:\n",
    "        f.write(token + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
